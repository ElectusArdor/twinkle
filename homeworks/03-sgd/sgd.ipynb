{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flexible-madness",
   "metadata": {},
   "source": [
    "# Градиентный спуск (15 баллов)\n",
    "\n",
    "В этой домашней работе мы попробуем разобраться в том, что же такое градиентный спуск, как он работает и что можно делать с его помощью. Обычно для этих целей используются пара готовых классов из `sklearn`: `SGDClassifier` и `SGDRegressor`, на основании которых написано еще много чего интересного. Можно было бы воспользоваться этими классами и, подражая обезьяне, пробовать крутить различные ручки-параметры, пытаясь понять, что же они значат и как работают. Но это не наш путь, поэтому мы напишем все сами.\n",
    "\n",
    "## Что будем делать\n",
    "\n",
    "Градиентный спуск это основной метод оптимизации в машинном обучении, и он нам еще не раз пригодится. Чтобы не терять свои наработки в дюжине тетрадок, мы напишем свою упрощенную версию библиотеки `sklearn`, добавляя туда функционал от домашки к домашке. Скелет нашего фреймворка в самом начале будет крутиться вокруг трех классов:\n",
    "\n",
    "`_losses.py` -- функции потерь для различных линейных моделей. Каждая функция потерь имеет два метода: `loss`, который непосредственно вычисляет значение функции потерь, и `dloss`, который вычисляет значение ее производной (градиента). В качестве аргументов эти функции принимают предсказанное значение `p` и истинное значение `y` для объекта.\n",
    "\n",
    "`_sgd.py` -- основа основ, тут находится метод `sgd`, который для полученной лосс функции проходит `epochs` итераций градиентного спуска, обновляя полученные веса и смещения на основании входных данных. Основную часть работы мы будем вести здесь.\n",
    "\n",
    "`SGDRegressor.py` -- обертка над `sgd`, обрабатывает входные данные и реализует интерфейсы, принятые в `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-double",
   "metadata": {},
   "source": [
    "# SquaredLoss (0.5 балла)\n",
    "\n",
    "Чтобы в домашку было проще вкатится, мы начнем с малого, а именно -- реализуем квадратичную функцию потерь. Как мы помним из теории, квадратичная функция потерь на вход принимает два числа (`p` и `y` в нашем случае), а зачем вычисляется по следующей формулe:\n",
    "\n",
    "$SE = (y - \\hat{y})^2$, где $\\hat{y}$ это наше предсказание, или $p$.\n",
    "\n",
    "Для каждого $i$-го объекта лосс вычисляется по следующей формуле:\n",
    "\n",
    "$L\\left(y_i, f(x_i)\\right) = \\frac{1}{2}\\left(y_i - f(x_i)\\right)^2$ или $L(y_i, p_i) = \\frac{1}{2}\\left(y_i - p_i\\right)^2$\n",
    "\n",
    "Для начала реализуйте эту формулу и ее производную в заранее подготовленном классе `SquaredLoss`, который можно найти в `_losses.py`. Места где от вас хотят что-то увидеть помечены строчкой `<YOUR CODE HERE>`. Сам класс выглядит примерно вот так:\n",
    "\n",
    "Ячейку ниже править не надо, она только для примера, пишите код в `_losses.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquaredLoss(RegressionLoss):\n",
    "    def loss(self, p: float, y: float) -> float:\n",
    "        # <YOUR CODE HERE>\n",
    "\n",
    "    def dloss(self, p: float, y: float) -> float:\n",
    "        # <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-means",
   "metadata": {},
   "source": [
    "После этого, чтобы удостоверится в правильности реализации формул, прогоните тесты для проверки. Это можно сделать как в ячейке ниже, так и в консоли, запустив следующую команду:\n",
    "\n",
    "`pytest test_sgd.py -k TestSquaredLoss -v`\n",
    "\n",
    "Для запуска в ячейке перед командой введите восклицательный знак (просто запустите ячейку ниже, он там уже есть). Для проверки конечно было бы удобно, если бы все такие ячейки были выполнены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestSquaredLoss -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-tradition",
   "metadata": {},
   "source": [
    "Как понять, что все прошло успешно? Есть несколько признаков\n",
    "\n",
    "* `test_gd.py ..` -- справа от имени файла с тестом только точки, никаких букв `F`;\n",
    "* `[100%]` -- еще правее цифра 100%;   \n",
    "* В полосе снизу написано `2 passed`, нет слова `failed` и она зеленого цвета, а не красного. \n",
    "\n",
    "Если что-то пошло не так, проверьте свой код и посмотрите в тесты еще раз. Повторяйте до сходимости, после чего переходите к следующему пункту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-adventure",
   "metadata": {},
   "source": [
    "# SGD (2 балла)\n",
    "\n",
    "Теперь мы перейдем к основной части нашей работы -- алгоритму стохастического градиентного спуска. Заготовка функции, в которой мы его реализуем лежит в `sgd.py`. Не пугайтесь, хоть там и много аргументов, все они описаны в докблок комментарии в начале функции. Нас сейчас будут интересовать далеко не все, а только самые необходимые для работы:\n",
    "\n",
    "* `weights` -- вектор весов линейной модели (если кто помнит, их количество равно количеству признаков);\n",
    "* `intercept` -- bias, смещение плоскости относительно нуля;\n",
    "* `loss` -- класс, реализующий интерфейс функции потерь, такую мы уже реализовали выше;\n",
    "* `X` -- список объектов из тренировочной выборки;\n",
    "* `y` -- список таргетов для этих объектов;\n",
    "* `max_iter` -- максимальное количество итераций (или шагов, или *эпох*) градиентного спуска;\n",
    "* `fit_intercept` -- обучать ли смещение (intercept) или нет\n",
    "* `eta0` -- под этим странным именем скрывается скорость обучения, или *learning rate*.\n",
    "\n",
    "Для решения этой задачи напомню алгоритм стохастического градиентного спуска в рамках регрессии, которую мы решаем:\n",
    "\n",
    "## Математическая формулировка\n",
    "\n",
    "Дано множество объектов $(x_1, y_1), ..., (x_n, y_n)$, где $x_i\\in\\mathbb{R}^m$ и $y_i\\in\\mathbb{R}$. Наша цель -- обучить линейную модель $f(x) = w^Tx + b$ с весами $w\\in\\mathbb{R}^m$ и смещением $b\\in\\mathbb{R}$. Для того, чтобы найти эти параметры, мы минимизируем регуляризованную ошибку на тренировочной выборке:\n",
    "\n",
    "$E(w, b) = \\frac{1}{n}\\sum_{i=1}^{n}L(y_i, f(x_i)) + \\alpha R(w)$,\n",
    "\n",
    "где $L$ это функция потерь, а $R$ это регуляризатор. $\\alpha > 0$ это неотрицательный параметр, который контролирует силу регуляризации. В этой домашней работе мы будем считать, что $\\alpha = 0$ и регуляризация не используется.\n",
    "\n",
    "В качестве алгоритма минимизации используется стохастический градиентный спуск (stochastic gradient descent, SGD). SGD аппроксимирует истинное значение ошибки $E(w, b)$ рассматривая по одному объекту из тренировочный выборки за раз. Алгоритм перебирает все объекты тренировочный выборки и для каждого обновляет параметры модели в соответствии с правилами, описанными следующими формулами:\n",
    "\n",
    "$w\\leftarrow w -\\eta\\left[\\frac{\\partial{L(w^Tx_i + b, y_i)}}{\\partial{w}}\\right]$\n",
    "\n",
    "$b\\leftarrow b -\\eta\\left[\\frac{\\partial{L(w^Tx_i + b, y_i)}}{\\partial{b}}\\right]$\n",
    "\n",
    "На более понятном языке это можно выразить так:\n",
    "1. Вычислите значение линейной функции для $x_i$ объекта;\n",
    "2. Вычислите градиент функции потерь (часть этого уже готова в предыдущем пункте);\n",
    "3. Обновите параметры модели $w$ и $b$ (`weights` и `intercept`). Не забудьте про learning rate.\n",
    "\n",
    "После того, как все покажется максимально понятным, реализуйте это в коде. Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*):\n",
    "\n",
    "`pytest test_sgd.py -k TestSgdFn -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestSgdFn -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-rough",
   "metadata": {},
   "source": [
    "# SGDRegressor (2 балла)\n",
    "\n",
    "После того, как мы написали ядро модели, напишем и обертку, подражая интерфейсу `sklearn.linear_model.SGDRegressor`. Для начала стоит определить конструктор класса, который принимает параметры `loss`, `fit_intercept`, `max_iter` и `eta0`. Обратите внимание, что для удобства лосс функцию нужно передавать строкой, а на основании этого решать, какой класс для ее вычисления использовать.\n",
    "\n",
    "Обратите внимание, что все таким классы имеют по умолчанию значения для ***всех*** параметров. Это нужно, чтобы с таким интерфейсом было удобно работать из коробки, в несколько секунд создавая модель:\n",
    "\n",
    "`reg = SGDRegressor()`\n",
    "\n",
    "Это удобно, ведь мы можем каждый раз переопределять только те параметры, которые нам нужны. По для значения `fit_intercept` по умолчанию нужно выставить `True`, для `max_iter` -- тысячу, а для `eta0` -- одну сотую.\n",
    "\n",
    "Интерфейс практически любой модели машинного обучения с учителем в `scikit-learn` имеет два главных метода:  \n",
    "`fit(X, y)` -- принимает матрицу объекты-признаки и вектор таргетов тренировочной выборки, запускает процесс обучения;  \n",
    "`predict(X)` -- принимает матрицy объекты-признаки тестовой выборки, выдает предсказания для полученных объектов. \n",
    "\n",
    "В этой части нужно будет реализовать методы конструктор класса, а также методы `fit` и `predict`. Задача тут стоит простая -- инициализировать параметры модели и передать их в уже готовый написанный метод `sgd`. Цель всего этого -- просто понять, как разделяется ответственность между функцией с алгоритмом и обвязкой в виде класса.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*):\n",
    "\n",
    "`pytest test_sgd.py -k TestSGDRegressor -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestSGDRegressor -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-congo",
   "metadata": {},
   "source": [
    "Если все тесты проходят, то вы справились с этой задачей. Поздравляю, вы написали свою первую модель машинного обучения руками с нуля, а это все-таки нетривиальная задачка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-dance",
   "metadata": {},
   "source": [
    "# Взрыв градиента (gradient explosion) (0.5 балла)\n",
    "\n",
    "Давайте испробуем нашу самописную модель на реальных данных и поглядим, как оптимизируются веса модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from SGDRegressor import SGDRegressor\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "reg = SGDRegressor().fit(X, y)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-participation",
   "metadata": {},
   "source": [
    "Огонь! Не переживайте, если вы увидите здесь вектор `nan` (а вы его здесь увидите). Если тесты прошли -- вы все сделали правильно,поэтому давайте подумаем, как мы пришли к жизни такой. Для этого посмотрим, как изменяются веса в зависимости от количества пройденных эпох.\n",
    "\n",
    "*Кстати, если вам повезет, то вы увидите красное предупреждение о недопустимом значении при умножении в вычислении весов.*\n",
    "\n",
    "Для удобства отладки добавим еще один булев параметр в класс `SGDRegressor`, а называется он `verbose`. Он будет отвечать за *многословность* нашей модели, и в verbose-режиме модель будет выдавать отладочную информацию. Этот же параметр прокиньте в функцию `sgd`, благо там он уже есть, и даже есть пример его использования.\n",
    "\n",
    "После этого добавьте отладочный вывод градиента `dloss` на каждом ***объекте*** при включенном параметре `verbose` (не забудьте передать его в вызове `sgd` внутри метода `fit`). Для этого воспользуйтесь заготовкой функции `print_dloss` в том же файле `_sgd.py`. Чтобы не выводить пачку лишних nan, добавьте в функции условие проверку на nan наравне с `verbose`. Здесь вам предстоит потренироваться в сложнейшем написании условия и форматированном выводе питона, чтобы все выглядело красиво.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*):\n",
    "\n",
    "`pytest test_sgd.py -k TestPrintDloss -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestPrintDloss -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-azerbaijan",
   "metadata": {},
   "source": [
    "Ну а теперь еще разок запустим обучение на одну эпоху и включенным параметром `verbose`:\n",
    "\n",
    "*Подсказка: если выводятся только номера эпох, а градиентов нет -- перезапустите тетрадку: сверху в меню Kernel: Resart.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-central",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from SGDRegressor import SGDRegressor\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "reg = SGDRegressor(max_iter=1, verbose=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-upset",
   "metadata": {},
   "source": [
    "А теперь посмотрите на значения градиента и напишите ниже ответы на несколько вопросов:\n",
    "* Как изменяется значение градиента?\n",
    "* Какое последнее значение лосса выведено, до того как стало `nan`?\n",
    "* Что просходит с весами при таких значениях градиента?\n",
    "* Почему происходит взрыв градиента?\n",
    "* Как бороться с этим взрывом?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-taiwan",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "different-footwear",
   "metadata": {},
   "source": [
    "# Масштабирование признаков (5 баллов)\n",
    "\n",
    "## MaxAbsScaler (1 балл)\n",
    "\n",
    "Как мы уже поняли, недостатком нашего алгоритма является чувствительность к масштабированию признаков. Немасштабированные признаки могут иметь огромные значения от минус до плюс бесконечности. Самый простой способ уменьшить их разброс -- найти максимальное значение каждого признака среди всех объектов, запомнить его, после чего разделить значение каждого признака на это максимальное значение. После этого значения признаков будет в диапазоне $[-1.0, 1.0]$, а максимальное абсолютное значение каждого признака не будет превышать $1.0$.\n",
    "\n",
    "Реализуйте эту логику в классе `MaxAbsScaler`, заготовку которого можно найти в файле `MaxAbsScaler.py`. Что делают тесты:\n",
    "1. `test_fit_chainable` проверяет, что метод `fit` возвращает указатель на сам объект модели;\n",
    "2. `test_fit_n_samples_seen` проверяет, что вызов `fit` записывает в атрибут `n_samples_seen_` объекта модели количество объектов в обучающей выборке;\n",
    "3. `test_fit_max_abs_*` проверяют, что метод `fit` записывает в атрибут `max_abs_` вектор максимальных по модулю значений каждого признака;\n",
    "4. `test_fit_scale_*` проверяют, что метод `fit` записывает в атрибут `scale_` вектор масштабов для приведения признаков в диапазон $[-1.0, 1.0]$. В дальнейшем этот вектор поэлементно домножается на вектор признаков, который мы хотим отмасштабировать;\n",
    "5. `test_transform_*` проверяют, что метод `transform`, верно масштабирует матрицу объектов на входе с помощью обученных параметров скейлера;\n",
    "5. `test_fit_transform_*` проверяют, что метод `fit_transform` работает одновременно и как `fit` (обучает параметры модели), и как `transform` (преобразует входные данные).\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestMaxAbsScaler -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southern-temple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.7, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 -- /usr/local/opt/python@3.9/bin/python3.9\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/khlevnov/projects/sklearn-from-scratch/03_sgd\n",
      "collected 72 items / 62 deselected / 10 selected                               \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_chainable \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 10%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_n_samples_seen \u001b[32mPASSED\u001b[0m\u001b[32m            [ 20%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_max_abs_easy \u001b[32mPASSED\u001b[0m\u001b[32m              [ 30%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_max_abs_from_docs \u001b[32mPASSED\u001b[0m\u001b[32m         [ 40%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_scale_easy \u001b[32mPASSED\u001b[0m\u001b[32m                [ 50%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_scale_from_docs \u001b[32mPASSED\u001b[0m\u001b[32m           [ 60%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_transform_easy \u001b[32mPASSED\u001b[0m\u001b[32m                [ 70%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_transform_from_docs \u001b[32mPASSED\u001b[0m\u001b[32m           [ 80%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_transform_easy \u001b[32mPASSED\u001b[0m\u001b[32m            [ 90%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_transform_from_docs \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m62 deselected\u001b[0m\u001b[32m in 1.55s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestMaxAbsScaler -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-queue",
   "metadata": {},
   "source": [
    "Давайте попробуем воспользоваться нашим скейлером, чтобы решить задачу регрессии на тех же данных, что и раньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from MaxAbsScaler import MaxAbsScaler\n",
    "from SGDRegressor import SGDRegressor\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X = MaxAbsScaler().fit_transform(X)\n",
    "reg = SGDRegressor(max_iter=1).fit(X, y)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-essence",
   "metadata": {},
   "source": [
    "Работает ли теперь наша модель и взрываются ли веса? Почему? Напишите, что вы думаете об этом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-leisure",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-grass",
   "metadata": {},
   "source": [
    "## Метрики качества регрессии: MAE и MSE (1 балл)\n",
    "\n",
    "Теперь, когда все хоть как-то работает, стоит измерить качество модели. Для этого воспользуемся всем известными средней абсолютной и квадратичной ошибками, измерять которые будем на отложенной выборке.\n",
    "\n",
    "Реализуйте эти две метрики в файле `metrics.py` в соответствующих заготовках функций `mean_absolute_error` и `mean_squared_error`. Что делают тесты:\n",
    "1. `test_absolute_easy` проверяет, что функция `mean_absolute_error` работает корректно;\n",
    "1. `test_squared_easy` проверяет, что функция `mean_squared_error` работает корректно;\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestMetrics -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "checked-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.7, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 -- /usr/local/opt/python@3.9/bin/python3.9\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/khlevnov/projects/sklearn-from-scratch/03_sgd\n",
      "collected 72 items / 70 deselected / 2 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestMetrics::test_absolute_easy \u001b[31mFAILED\u001b[0m\u001b[31m                      [ 50%]\u001b[0m\n",
      "test_sgd.py::TestMetrics::test_squared_easy \u001b[31mFAILED\u001b[0m\u001b[31m                       [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________ TestMetrics.test_absolute_easy ________________________\u001b[0m\n",
      "\n",
      "self = <test_sgd.TestMetrics object at 0x128e6d820>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_absolute_easy\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[94massert\u001b[39;49;00m mean_absolute_error(np.array([\u001b[94m0\u001b[39;49;00m]), np.array([\u001b[94m0\u001b[39;49;00m])) == \u001b[94m0\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_sgd.py\u001b[0m:756: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "y_true = array([0]), y_pred = array([0])\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mmean_absolute_error\u001b[39;49;00m(y_true, y_pred):\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmetrics.py\u001b[0m:2: NotImplementedError\n",
      "\u001b[31m\u001b[1m________________________ TestMetrics.test_squared_easy _________________________\u001b[0m\n",
      "\n",
      "self = <test_sgd.TestMetrics object at 0x128e732b0>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_squared_easy\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[94massert\u001b[39;49;00m mean_squared_error(np.array([\u001b[94m0\u001b[39;49;00m]), np.array([\u001b[94m0\u001b[39;49;00m])) == \u001b[94m0\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_sgd.py\u001b[0m:766: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "y_true = array([0]), y_pred = array([0])\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mmean_squared_error\u001b[39;49;00m(y_true, y_pred):\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmetrics.py\u001b[0m:5: NotImplementedError\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_sgd.py::TestMetrics::test_absolute_easy - NotImplementedError\n",
      "FAILED test_sgd.py::TestMetrics::test_squared_easy - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[33m70 deselected\u001b[0m\u001b[31m in 1.86s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestMetrics -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-trigger",
   "metadata": {},
   "source": [
    "Разбейте выборку на трейн и тест, обучите модель на трейне с параметрами по умолчанию, получите предсказания на тестовой выборке. Посчитайте метрики на отложенной выборке, выведите их значения.\n",
    "\n",
    "*Подсказка: после этого заверните все это в функцию с одним параметром, через который в нее можно передать объект скейлера. Она нам еще пригодится.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-permit",
   "metadata": {},
   "source": [
    "Напишите ниже ответы на следующие вопросы:\n",
    "* Что вы думаете о полученных значениях?\n",
    "* Много это или мало, хорошо или плохо?\n",
    "* На чем лучше фитить скейлер: на всем датасете или только на трейне?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-skill",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-halloween",
   "metadata": {},
   "source": [
    "## MinMaxScaler (1 балл)\n",
    "\n",
    "Предыдущий способ масштабирования работает, и работает относительно неплохо -- по крайней мере модель как-то обучается. Хорошо она обучается или плохо мы посмотрим чуть позже, а пока займемся написанием еще пары классов для маcштабирования признаков.\n",
    "\n",
    "`MinMaxScaler` масштабирует признаки в заданный диапазон значений `[min, max]`, по умолчанию это `[0, 1]`, который передается как параметр конструктора -- `feature_range`. Работает скейлер весьма просто. Для начала нужно найти масштаб: взять разность между максимальным и минимальным значениями диапазона, в который мы масштабируем (`feature_range`), а потом разделить её на разность максимального и минимального значений по каждому признаку. После этого нужно отмасштабировать минимальные значения каждого признака и вычесть их из начала заданного диапазона, в который мы масштабируем. Потом для преобразования данных мы просто должны умножить каждый признак на масштаб и прибавить к нему минимальные значения из предыдущего шага.\n",
    "\n",
    "Реализуйте эту логику в классе `MinMaxScaler`, заготовку которого можно найти в файле `MinMaxScaler.py`. Что делают тесты:\n",
    "1. `test_fit_chainable` проверяет, что метод `fit` возвращает указатель на сам объект модели;\n",
    "2. `test_fit_n_samples_seen` проверяет, что вызов `fit` записывает в атрибут `n_samples_seen_` объекта модели количество объектов в обучающей выборке;\n",
    "3. `test_fit_data_min` проверяет, что метод `fit` записывает в атрибут `data_min_` вектор минимальных значений каждого признака;\n",
    "4. `test_fit_data_max` проверяет, что метод `fit` записывает в атрибут `data_max_` вектор максимальных значений каждого признака;\n",
    "5. `test_fit_data_range` проверяет, что метод `fit` записывает в атрибут `data_range_` вектор разницы между максимальными и минимальными значениями каждого признака, см. пункты выше;\n",
    "6. `test_fit_scale` проверяет, что метод `fit` записывает в атрибут `scale_` масштаб для каждого признака. Он вычисляется как отношение разницы максимального и минимального значений данного диапазона `feature_range` из конструктора к разбросу значений на данных из предыдущего пункта. *Подсказка: если вам где-то захочется поделить на ноль, замените его единичкой*;\n",
    "7. `test_fit_min` проверяет, что метод `fit` записывает в атрибут `min_` вектор значений для корректировки к минимуму. Он вычисляется как разность минимального значения из диапазона `feature_range` и отмасштабированных минимальных значений каждого признака;\n",
    "8. `test_fit_in_feature_range` проверяет, что метод `fit` корректно работает при передаче диапазона значений, отличных от значений по умолчанию $[0, 1]$;\n",
    "9. `test_transform` проверяет, что метод `transform` корректно масштабирует данные, используя обученные параметры скейлера;\n",
    "10. `test_fit_transform` проверяет, что метод `fit_transform` корректно обучает параметры скейлера и корректно масштабирует полученные данные.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestMinMaxScaler -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestMinMaxScaler -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-poison",
   "metadata": {},
   "source": [
    "## StandardScaler (1 балл)\n",
    "\n",
    "К третьему скейлеру вы должны были задуматься над следующим вопросом: \"Зачем нам столько разных?\". Мы сравним их чуть позже, а пока давайте допишем последний. Он масштабирует признаки вычитая среднее и деля на стандартное отклонение по следующей формуле:\n",
    "\n",
    "$z = \\frac{(x - u)}{s}$, где $u$ это среднее значение признака по выборке, а $s$ это стандартное отклонение этого признака.\n",
    "\n",
    "Этот скейлер должен принимать два аргумента:  \n",
    "`with_mean` -- включает вычисление среднего, иначе среднее -- 0;  \n",
    "`with_std` -- включает вычисление стандартного отклонения, иначе отклонение -- 1.\n",
    "\n",
    "Реализуйте эту логику в классе `StandardScaler`, заготовку которого можно найти в файле `StandardScaler.py`. Что делают тесты:\n",
    "1. `test_fit_chainable` проверяет, что метод `fit` возвращает указатель на сам объект модели;\n",
    "2. `test_fit_n_samples_seen` проверяет, что вызов `fit` записывает в атрибут `n_samples_seen_` объекта модели количество объектов в обучающей выборке;\n",
    "3. `test_fit_mean` проверяет, что метод `fit` записывает в атрибут `mean_` вектор средних значений по каждому признаку;\n",
    "4. `test_fit_var` проверяет, что метод `fit` записывает в атрибут `var_` вектор стандартных отклонений по каждому признаку;\n",
    "5. `test_fit_var_without_std` проверяет, что метод `fit` записывает в атрибут `var_` значение `None` при выключенном флаге `with_std`;\n",
    "6. `test_fit_mean_var_without_mean_std` проверяет, что метод `fit` записывает в атрибуты `mean_` и `var_` значения `None` при выключенных флагах `with_mean` и `with_std`;\n",
    "7. `test_fit_scale` проверяет, что метод `fit` записывает в атрибут `scale_` вектор масштабов каждого признака;\n",
    "8. `test_fit_scale_without_std` проверяет, что метод `fit` записывает в атрибут `scale_` значение `None` при выключенном флаге `with_std`;\n",
    "9. `test_fit_scale_without_mean_std` проверяет, что метод `fit` записывает в атрибут `scale_` значение `None` при выключенных флагах `with_mean` и `with_std`;\n",
    "10. `test_transform` проверяет, что метод `transform` корректно масштабирует данные, используя обученные параметры скейлера;\n",
    "11. `test_transform_without_std` проверяет, что метод `transform` корректно масштабирует данные, используя обученные параметры скейлера (при выключенном параметре флаге `with_std`);\n",
    "12. `test_transform_without_mean_std` проверяет, что метод `transform` корректно масштабирует данные, используя обученные параметры скейлера (при выключенных флагах `with_mean` и `with_std`);\n",
    "13. `test_fit_transform` проверяет, что метод `fit_transform` корректно обучает параметры скейлера и корректно масштабирует полученные данные.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestStandardScaler -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestStandardScaler -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-providence",
   "metadata": {},
   "source": [
    "## Чем лучше масштабировать? (1 балл)\n",
    "\n",
    "Давайте сравним наши способы масштабировать признаки, обучив регрессор со всеми тремя алгоритмами. Вычислите MAE и MSE для каждого скейлера на тестовых данных, сравните их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-andrews",
   "metadata": {},
   "source": [
    "Ответьте на следующие вопросы:\n",
    "* Сильно ли отличаются результаты?\n",
    "* Появился ли смысл в значениях средней абсолютной и квадратичной ошибок в рамках этой задачи?\n",
    "* Какой метод масштабирования работает лучше всех?\n",
    "* Какой хуже всех? Как вам кажется, почему?\n",
    "* Каким будете пользоваться в дальнейшем? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-elizabeth",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "played-issue",
   "metadata": {},
   "source": [
    "# Бонус: снова SGD (5 баллов)\n",
    "\n",
    "Настало время расширить наш игрушечный алгоритм, доведя его до ума. Для этого надо добавить еще несколько фич.\n",
    "\n",
    "## Случайный выбор объектов. Shuffle (1 балл)\n",
    "\n",
    "Пока что наша модель не совсем соответствует алгоритму стохастического градиентного спуска, ведь мы перебираем элементы всегда в одном и том же порядке. В этой части вам необходимо добавить случайность в выборе элементов внутри одной эпохи при условии, что каждый элемент будет выбран ровно один раз.\n",
    "\n",
    "Однако перемешивание элементов дело непростое, и для удобства тестирование должно быть воспроизводимым. Для этого нужно дополнительно передавать в модель зерно генератора псевдослучайных чисел. Добавьте в конструктор `SGDRegressor` булев параметр `shuffle` и сделайте его по умолчанию равным `True`. Еще добавьте целочисленный параметр `random_state`, равный по умолчанию `None`. После прокиньте их в функцию `sgd` внутри метода `fit`.\n",
    "\n",
    "Внутри `sgd` в зависимости от флага `shuffle` создавайте ГПСЧ с заданным зерном и добавьте случайный выбор следующего элемента. Зерно генератора случайных чисел соответствует параметру `seed` внутри функции `_sgd`. Помните, что каждый элемент должен поучаствовать в градиентном спуске один раз в каждой эпохе.\n",
    "\n",
    "*Подсказка: проще сначала написать реализацию в функции `sgd`, простестировать ее, и после прокинуть параметры снаружи из `SGDRegressor`.*\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestShuffle -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestShuffle -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-thought",
   "metadata": {},
   "source": [
    "## Дообучение модели. Partial fit (1 балл)\n",
    "\n",
    "В `scikit-learn` некоторые модели включают в себя себя следующий метод:\n",
    "\n",
    "`partial_fit(X, y)` -- принимает матрицу объекты-признаки и вектор таргетов, обновляет веса модели, проходя градиентным спуском по новой пачке данных. Внутри этот метод реализуется как тот же `fit`, только не обнуляет веса *(параметры модели)* и прогоняет ***одну итерацию*** градиентного спуска по новым данным.\n",
    "\n",
    "В этой части реализуйте метод `partial_fit(X, y)`, который прогоняет одну эпоху градиентного спуска по своим аргументам, пользуясь уже обученными параметрами модели. Вы можете создать новый приватный метод `__partial_fit` (начинается с подчеркивания), который наравне с матрицей объекты-признаки и вектором таргетов принимает количество эпох. В него можно перетащить содержимое `fit`, а дальше уже использовать этот новый метод как внутри `fit` с (`max_iter=max_iter`), так и внутри `partial_fit` (c `max_iter=1`). Таким образом не придется делать два больших вызова `sgd` дважды.\n",
    "\n",
    "Реализуйте эту логику в классе `SGDRegressor`. Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestPartialFit -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestPartialFit -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-recorder",
   "metadata": {},
   "source": [
    "## Горячий старт. Warm start (1 балл)\n",
    "\n",
    "Иногда обучение модели занимает достаточно очень много времени. Представим ситуацию: мы подбираем гиперпараметры модели, и на каждом этапе не очень то хочется учить модель с нуля, ведь нам достаточно обучить одну модель, а все остальные начинать обучать уже не с начала, а используя параметры обученной модели. С такой же ситуацией можно столкнуться, когда мы закончили обучение, но нам хочется прогнать еще сотню-другую эпох в надежде, что качество вырастет. Сейчас в нашей модели можем вызывать метод `fit` заново, но это приводит к паре проблем:\n",
    "1. Нет возможности выучить ту же модель на новых данных с нуля (со сбросом параметров к начальным);\n",
    "2. Нет возможности передать веса в модель перед обучением.\n",
    "\n",
    "Итак, хочется иметь возможность брать параметры обученной модели и передавать их в новую модель. Как же это можно сделать? Давайте добавим в конструктор булев параметр `warm_start` (по умолчанию `False`), и в зависимости от него будем решать, оставлять или сбрасывать параметры модели при перезапусках `fit`. Кроме того, нужно добавить в `fit` два параметра: `coef_init` и `intercept_init`, оба по умолчанию `None`. В них можно будет передать начальные значения весов и смещение.\n",
    "\n",
    "Алгоритм будет прост: если параметр `warm_start` включен, то при перезапуске `fit` мы пытаемся взять аргументы `coef_init` и `intercept_init` в качестве исходных значений весов и смещений. Если один из них пуст, то берем в качестве исходных уже готовые параметры нашей модели. Если `warm_start` выключен, то генерируем параметры заново, как мы уже делали до этого.\n",
    "\n",
    "Реализуйте эту логику в классе `SGDRegressor`. Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestWarmStart -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestWarmStart -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-strengthening",
   "metadata": {},
   "source": [
    "## Взвешивание объектов. Sample weights (1 балл)\n",
    "\n",
    "Иногда может оказаться, что не все объекты одинаково важны для обучения модели. Допустим у нас есть датасет с банковскими операциями, по которому мы должны научиться определять мошеннические операции. В этой выборке будут значительно преобладать законные операции, а мошеннических будет не так много (это кажется очевидным, если представить огромное количество операций в банке). Хочется сделать так, чтобы редко встречающиеся мошеннические операции помогали нам быстрее сдвигать градиент в нужную сторону, а значит и обучаться быстрее.\n",
    "\n",
    "Чтобы воспользоваться этим, хочется увеличить удельный вес таких редких объектов в выборке. Это можно сделать двумя путями: либо чаще показывать такие объекты, либо добавить число, которое характеризует вес каждого такого объекта в общей выборке.\n",
    "\n",
    "Здесь мы реализуем вторую идею с весам: добавим параметры `sample_weight` в методы `fit` и `partial_fit` (по умолчанию `None`), откуда будем передавать их в `sgd`. Внутри `sgd` же мы будем использовать вес каждого объекта, измненяя градиент на этом объекте пропорционально его весу.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestSampleWeights -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestSampleWeights -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-carpet",
   "metadata": {},
   "source": [
    "## Коэффициент детерминации. $R^2$ (1 балл)\n",
    "\n",
    "Выше мы уже реализовали метрики MAE и MSE, но они страдают одной проблемой -- они неинтерпретируемы. Поправим это дело.\n",
    "\n",
    "У обертки реализуйте метод `score(X, y)`, который вычисляет коэффициент детерминации для своих аргументов. Вычисление должно происходить в два этапа: сначала внутри этого метода модель вычисляет предсказания для данного `X`, после чего вызывает функцию `r2_score`, которая вычисляет метрику на предсказанных значениях и таргетах.\n",
    "\n",
    "Для начала реализуйте метрику `r2_score`, заготовку которой можно найти в файле `metrics.py`. После этого реализуйте описанную выше логику в методе `score` класса `SGDRegressor`. Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestR2Score -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_sgd.py -k TestR2Score -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-praise",
   "metadata": {},
   "source": [
    "Подготовьте тренировочную и тестовые выборки, обучите на них модель, измерьте качество с помощью новой метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from StandardScaler import StandardScaler\n",
    "from SGDRegressor import SGDRegressor\n",
    "\n",
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-governor",
   "metadata": {},
   "source": [
    "* Какое значение получилось?\n",
    "* Можно ли его как-то интерпретировать?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-extraction",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "engaged-sugar",
   "metadata": {},
   "source": [
    "# Продолжение следует\n",
    "\n",
    "Если вы успешно дошли до этой части, то вы проделали большую работу в плане понимания того, как работает алгоритм. Ковырять его мы продолжим в следующей домашней работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-mills",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
